{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2240cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454f44f",
   "metadata": {},
   "source": [
    "# Human Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd936d",
   "metadata": {},
   "source": [
    "# 1.0 Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56ad14",
   "metadata": {},
   "source": [
    "<h3> 1.1 Helper Methods to find wav file path and emotion </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad56386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the emotion label from audio title\n",
    "def get_emotion(filename):\n",
    "    # Emotion Tag\n",
    "    emote = filename.split('_')[2]\n",
    "    if emote=='ANG':\n",
    "        return 'angry'\n",
    "    elif emote=='DIS':\n",
    "        return 'disgust'\n",
    "    elif emote=='FEA':\n",
    "        return 'fear'\n",
    "    elif emote=='HAP':\n",
    "        return ('happy')\n",
    "    elif emote=='NEU':\n",
    "        return ('neutral')\n",
    "    else:\n",
    "        return ('sad')\n",
    "\n",
    "# Creates the main dataframe\n",
    "def create_dataframe(directory):\n",
    "    emotions = []\n",
    "    paths = []\n",
    "    # Loop through folder\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        # Get file complete path\n",
    "        f = os.path.join(directory, filename)\n",
    "        # Checks if path is a file or not   \n",
    "        if os.path.isfile(f):\n",
    "            emotions.append(get_emotion(filename))\n",
    "            paths.append(f)\n",
    "    # Output as Pandas Dataframe\n",
    "    return pd.DataFrame.from_dict({'Emotion':emotions,'Path':paths})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1d3f9",
   "metadata": {},
   "source": [
    "<h3> 1.2 Helper Methods to get the frequency values from wav file. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1597880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the frequencies for each path in the dataframe\n",
    "def get_data():\n",
    "    audios = []\n",
    "    samples = []\n",
    "    for x in tqdm(df['Path']):\n",
    "        # Cuts all audios to include the sound only\n",
    "        data, sampling = librosa.load(x, duration=2.5, offset=0.35)\n",
    "        audios.append(list(data))\n",
    "        samples.append(sampling)\n",
    "    return audios, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f98f5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7529a4532d4641d08333fabd5624715b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9cc562ed7c470096c9ba37f92e27a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get wav files path and emotion type\n",
    "df = create_dataframe('data/audio')\n",
    "# Get sound frequencies for each file\n",
    "audios, samples = get_data()\n",
    "# Append to a new column in dataframe\n",
    "df['freq'] = audios\n",
    "df['sampling'] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1883f45",
   "metadata": {},
   "source": [
    "# 2.0 Initial Feature Engineering\n",
    "\n",
    "This Jupyter Script contains the features individually for easy break down of each feature. For the more efficient run containing all the features please check the python file \"emotion_feature_engineering.py\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b4ef9",
   "metadata": {},
   "source": [
    "<h3> 2.1 Basic Statistics of time-series </h3>\n",
    "\n",
    "Which includes the Min, Max and Standard Deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597ebac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bbb57f60404e0888390771fe6711b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def std_value(xs):\n",
    "    xbar = sum(xs) / len(xs)\n",
    "    return math.sqrt(sum([(x - xbar) ** 2 for x in xs]) / len(xs))\n",
    "\n",
    "def basic_stats(xs):\n",
    "    minV =  min(xs)\n",
    "    maxV = max(xs)\n",
    "    std = std_value(xs)\n",
    "    return np.array([minV, maxV, std])\n",
    "\n",
    "# Calculates the basic stats without the need to repeat for each one\n",
    "stats = df['freq'].progress_apply(basic_stats).tolist()\n",
    "stats = np.array(stats)\n",
    "\n",
    "df['min_value'] = stats[:,0]\n",
    "df['max_value'] = stats[:,1]\n",
    "df['std_value'] = stats[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9c29c3",
   "metadata": {},
   "source": [
    "<h3> 2.2 Total Energy of Time-series </h3>\n",
    "\n",
    "$$X = \\sum \\limits _{n=1} ^{N} x_n^2$$\n",
    "where $x_n$ denotes each element from the time-series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4386dbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05485c955eba4cf8bf65868667e9fb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def total_energy(xs):\n",
    "    return sum([x**2 for x in xs])\n",
    "\n",
    "df['total_energy'] = df['freq'].progress_apply(total_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc7e1a",
   "metadata": {},
   "source": [
    "<h3> 2.3 Zero Crossing Rate </h3>\n",
    "\n",
    "(Rate at which a signal changes from positive to negative or vice versa)\n",
    "\n",
    "$$ ZCR = \\frac{1}{T - 1} \\sum \\limits _{t=1} ^{T-1} 1_{\\mathbb{R}_{<0}} (s_t s_{t-1})$$\n",
    "\n",
    "where $s$ is a signal of length $T$ and $1_{\\mathbb{R}_{<0}}$ is an indicator function where $<0$ is $1$ and $>0$ is $0$.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Zero-crossing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d68946e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1420592827e04c578934d447c4209801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Returns the number of times a signal changes from positive to negative or negative to positive\n",
    "def zero_crossing(xs):\n",
    "    xs = np.array(xs)\n",
    "    #'xs[1:]' is a list not containing the first element\n",
    "    #'xs[:-1]' is a list not containing the last element\n",
    "    return ((xs[1:] * xs[:-1]) < 0).sum()\n",
    "\n",
    "# Returns the rate for the zero crossing\n",
    "# In cases that the zero_crossing is not calculated this function can handle it \n",
    "def zero_crossing_rate(xs, precompute=None):\n",
    "    if (precompute == None):\n",
    "        return (zero_crossing(xs) / (len(xs) - 1))\n",
    "    else:\n",
    "        return (precompute / (len(xs) - 1))\n",
    "\n",
    "def zero_crossing_stats(xs, both=True):\n",
    "    # Convert to numpy array\n",
    "    xs = np.array(xs)\n",
    "    # Zero Crossing Count\n",
    "    z_crossing_val = zero_crossing(xs)\n",
    "    # Zero Crossing Rate\n",
    "    z_crossing_rate_val = zero_crossing_rate(xs, precompute=z_crossing_val)\n",
    "    return np.array([z_crossing_val, z_crossing_rate_val])\n",
    "\n",
    "# Calculates the values without the need to repeat for each one\n",
    "crossing_stats = df['freq'].progress_apply(zero_crossing_stats).tolist()\n",
    "crossing_stats = np.array(crossing_stats)\n",
    "\n",
    "df['zero_crossing'] = crossing_stats[:,0]\n",
    "df['zero_crossing_rate'] = crossing_stats[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bcb859",
   "metadata": {},
   "source": [
    "<h3> 2.4 RMS (Root Mean Square) </h3>\n",
    "\n",
    "$$ RMS = \\sqrt{\\frac{1}{N} (\\sum \\limits _{n=0} ^{N} x_n^2)}$$\n",
    "\n",
    "where $x_n$ denotes each element from the time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfcb00ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c881d0947a74c419fc4f34168f1252e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rms(xs):\n",
    "     return math.sqrt(sum([x**2 for x in xs]) / len(xs))\n",
    "    \n",
    "df['rms'] = df['freq'].progress_apply(rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8a71f",
   "metadata": {},
   "source": [
    "<h3> 2.5 Mel-frequency cepstral coefficients [MFCC] </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad3db362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(xs, sampling=22050):\n",
    "    xs = np.array(xs)\n",
    "    mfcc = librosa.feature.mfcc(y=xs, sr=sampling).T\n",
    "    # Gets the mean value for each Coefficient [Gets mean of column]\n",
    "    return list(np.mean(mfcc, axis=0))\n",
    "\n",
    "mfcc_features = []\n",
    "for x in df['freq']:\n",
    "    mfcc_features.append(mfcc(x))\n",
    "\n",
    "mfcc_features = np.array(mfcc_features)\n",
    "\n",
    "# convert to pandas dataframe and append to the main dataframe\n",
    "df = pd.concat([df, pd.DataFrame(mfcc_features, columns=['mfcc_%i' % i for i in range(20)])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e76bc0",
   "metadata": {},
   "source": [
    "<h3> 2.6 Mel Spectogram </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a529bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_spec(xs, sampling=22050):\n",
    "    xs = np.array(xs)\n",
    "    melspec = librosa.feature.melspectrogram(y=xs, sr=sampling).T\n",
    "    # Gets the mean value for each Coefficient [Gets mean of column]\n",
    "    return list(np.mean(melspec, axis=0))\n",
    "\n",
    "mel_spec_features = []\n",
    "for x in df['freq']:\n",
    "    mel_spec_features.append(mel_spec(x))\n",
    "\n",
    "mel_spec_features = np.array(mel_spec_features)\n",
    "\n",
    "columns = ['mel_spec_%i' % i for i in range(mel_spec_features[0].shape[0])]\n",
    "# convert to pandas dataframe and append to the main dataframe\n",
    "df = pd.concat([df, pd.DataFrame(mel_spec_features, columns=columns)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f4510",
   "metadata": {},
   "source": [
    "# 3.0 Initial Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a8baa1",
   "metadata": {},
   "source": [
    "<h3> 3.1 Creating Training and Testing Set </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b201ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[df.columns[4:]].copy()\n",
    "y = df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c54cda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Dataset\n",
    "X=(X-X.min())/(X.max()-X.min())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515090e",
   "metadata": {},
   "source": [
    "<h3> 3.2 ML Models </h3>\n",
    "\n",
    "<h3> Random Forest </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02732ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create Model\n",
    "model = RandomForestClassifier(verbose=1, max_depth=50, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "# Make Predictions\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee139aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46375248910322947\n",
      "0.47019230573230447\n",
      "0.45558644497709233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Evalulate Model\n",
    "print(precision_score(y_test, preds, average='macro'))\n",
    "print(recall_score(y_test, preds, average='macro'))\n",
    "print(f1_score(y_test, preds, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72446b",
   "metadata": {},
   "source": [
    "<h3> Gradient Boosting </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e9e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.5447            1.35m\n",
      "         2           1.5023            1.32m\n",
      "         3           1.4475            1.32m\n",
      "         4           1.4169            1.30m\n",
      "         5           1.3877            1.28m\n",
      "         6           1.3726            1.28m\n",
      "         7           1.3499            1.28m\n",
      "         8           1.3402            1.28m\n",
      "         9           1.3281            1.27m\n",
      "        10           1.3173            1.27m\n",
      "        20           1.2213            1.21m\n",
      "        30           1.1620            1.14m\n",
      "        40           1.1147            1.05m\n",
      "        50           1.0766           58.35s\n",
      "        60           1.0435           53.89s\n",
      "        70           1.0124           49.61s\n",
      "        80           0.9865           45.59s\n",
      "        90           0.9608           41.54s\n",
      "       100           0.9357           37.61s\n",
      "       200           0.7609            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Create Model\n",
    "model = GradientBoostingClassifier(verbose=1, n_estimators=200, learning_rate=1.0, max_depth=1)\n",
    "model.fit(X_train, y_train)\n",
    "# Make Predictions\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f06a72ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4784672212608357\n",
      "0.47904140090719866\n",
      "0.47827565914340786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(precision_score(y_test, preds, average='macro'))\n",
    "print(recall_score(y_test, preds, average='macro'))\n",
    "print(f1_score(y_test, preds, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
